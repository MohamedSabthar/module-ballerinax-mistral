// AUTO-GENERATED FILE. DO NOT MODIFY.
// This file is auto-generated by the Ballerina OpenAPI tool.

import ballerina/constraint;
import ballerina/data.jsondata;
import ballerina/http;

# Represents the Queries record for the operation: jobs_api_routes_fine_tuning_create_fine_tuning_job
public type JobsApiRoutesFineTuningCreateFineTuningJobQueries record {
    # * If `true` the job is not spawned, instead the query returns a handful of useful metadata
    #   for the user to perform sanity checks (see `LegacyJobMetadataOut` response).
    # * Otherwise, the job is started and the query returns the job ID along with some of the
    #   input parameters (see `JobOut` response)
    @http:Query {name: "dry_run"}
    boolean? dryRun?;
};

public type ToolCall record {|
    FunctionCall 'function;
    int index = 0;
    string id = "null";
    ToolTypes 'type?;
|};

public type JsonSchema record {|
    record {} schema;
    string name;
    string? description?;
    boolean strict = false;
|};

public type ChatCompletionChoice record {
    @jsondata:Name {value: "finish_reason"}
    "stop"|"length"|"model_length"|"error"|"tool_calls" finishReason;
    int index;
    AssistantMessage message;
};

public type ArchiveFTModelOut record {
    boolean archived = true;
    string id;
    "model" 'object = "model";
};

public type OCRResponse record {|
    # List of OCR info for pages
    OCRPageObject[] pages;
    # The model used to generate the OCR
    string model;
    @jsondata:Name {value: "usage_info"}
    OCRUsageInfo usageInfo;
|};

public type GithubRepositoryIn record {
    string owner;
    string? ref?;
    string name;
    @constraint:Number {minValueExclusive: 0}
    decimal weight = 1;
    "github" 'type = "github";
    string token;
};

public type EventOut record {
    record {}? data?;
    # The name of the event
    string name;
    # The UNIX timestamp (in seconds) of the event
    @jsondata:Name {value: "created_at"}
    int createdAt;
};

# Represents the Queries record for the operation: jobs_api_routes_fine_tuning_get_fine_tuning_jobs
public type JobsApiRoutesFineTuningGetFineTuningJobsQueries record {
    # The Weights and Biases project to filter on. When set, the other results are not displayed
    @http:Query {name: "wandb_project"}
    string? wandbProject?;
    # The Weight and Biases run name to filter on. When set, the other results are not displayed
    @http:Query {name: "wandb_name"}
    string? wandbName?;
    # The date/time to filter on. When set, the results for previous creation times are not displayed
    @http:Query {name: "created_after"}
    string? createdAfter?;
    # The model name used for fine-tuning to filter on. When set, the other results are not displayed
    string? model?;
    # The page number of the results to be returned
    int page = 0;
    # The model suffix to filter on. When set, the other results are not displayed
    string? suffix?;
    # When set, only return results for jobs created by the API caller. Other results are not displayed
    @http:Query {name: "created_by_me"}
    boolean createdByMe = false;
    # The number of items to return per page
    @http:Query {name: "page_size"}
    int pageSize = 100;
    # The current job state to filter on. When set, the other results are not displayed
    "QUEUED"|"STARTED"|"VALIDATING"|"VALIDATED"|"RUNNING"|"FAILED_VALIDATION"|"FAILED"|"SUCCESS"|"CANCELLED"|"CANCELLATION_REQUESTED"? status?;
};

public type FileSchema record {
    # The name of the uploaded file
    string filename;
    FilePurpose purpose;
    # The size of the file, in bytes
    int bytes;
    # The UNIX timestamp (in seconds) of the event
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The unique identifier of the file
    string id;
    Source 'source;
    @jsondata:Name {value: "sample_type"}
    SampleType sampleType;
    @jsondata:Name {value: "num_lines"}
    int? numLines?;
    # The object type, which is always "file"
    string 'object;
};

# The fine-tuning hyperparameter settings used in a fine-tune job
public type TrainingParametersIn record {
    @jsondata:Name {value: "fim_ratio"}
    decimal? fimRatio = 0.9;
    # (Advanced Usage) Weight decay adds a term to the loss function that is proportional to the sum of the squared weights. This term reduces the magnitude of the weights and prevents them from growing too large
    @jsondata:Name {value: "weight_decay"}
    decimal? weightDecay = 0.1;
    # The number of training steps to perform. A training step refers to a single update of the model weights during the fine-tuning process. This update is typically calculated using a batch of samples from the training dataset
    @jsondata:Name {value: "training_steps"}
    int? trainingSteps?;
    # A parameter describing how much to adjust the pre-trained model's weights in response to the estimated error each time the weights are updated during the fine-tuning process
    @jsondata:Name {value: "learning_rate"}
    decimal learningRate = 0.00010;
    decimal? epochs?;
    @jsondata:Name {value: "seq_len"}
    int? seqLen?;
    # (Advanced Usage) A parameter that specifies the percentage of the total training steps at which the learning rate warm-up phase ends. During this phase, the learning rate gradually increases from a small value to the initial learning rate, helping to stabilize the training process and improve convergence. Similar to `pct_start` in [mistral-finetune](https://github.com/mistralai/mistral-finetune)
    @jsondata:Name {value: "warmup_fraction"}
    decimal? warmupFraction = 0.05;
};

# Provides a set of configurations for controlling the behaviours when communicating with a remote HTTP endpoint.
@display {label: "Connection Config"}
public type ConnectionConfig record {|
    # Configurations related to client authentication
    http:BearerTokenConfig auth;
    # The HTTP version understood by the client
    http:HttpVersion httpVersion = http:HTTP_2_0;
    # Configurations related to HTTP/1.x protocol
    http:ClientHttp1Settings http1Settings = {};
    # Configurations related to HTTP/2 protocol
    http:ClientHttp2Settings http2Settings = {};
    # The maximum time to wait (in seconds) for a response before closing the connection
    decimal timeout = 30;
    # The choice of setting `forwarded`/`x-forwarded` header
    string forwarded = "disable";
    # Configurations associated with Redirection
    http:FollowRedirects followRedirects?;
    # Configurations associated with request pooling
    http:PoolConfiguration poolConfig?;
    # HTTP caching related configurations
    http:CacheConfig cache = {};
    # Specifies the way of handling compression (`accept-encoding`) header
    http:Compression compression = http:COMPRESSION_AUTO;
    # Configurations associated with the behaviour of the Circuit Breaker
    http:CircuitBreakerConfig circuitBreaker?;
    # Configurations associated with retrying
    http:RetryConfig retryConfig?;
    # Configurations associated with cookies
    http:CookieConfig cookieConfig?;
    # Configurations associated with inbound response size limits
    http:ResponseLimitConfigs responseLimits = {};
    # SSL/TLS-related options
    http:ClientSecureSocket secureSocket?;
    # Proxy server related options
    http:ProxyConfig proxy?;
    # Provides settings related to client socket configuration
    http:ClientSocketConfig socketConfig = {};
    # Enables the inbound payload validation functionality which provided by the constraint package. Enabled by default
    boolean validation = true;
    # Enables relaxed data binding on the client side. When enabled, `nil` values are treated as optional, 
    # and absent fields are handled as `nilable` types. Enabled by default.
    boolean laxDataBinding = true;
|};

public type FTModelCapabilitiesOut record {
    @jsondata:Name {value: "completion_chat"}
    boolean completionChat = true;
    @jsondata:Name {value: "function_calling"}
    boolean functionCalling = false;
    @jsondata:Name {value: "fine_tuning"}
    boolean fineTuning = false;
    @jsondata:Name {value: "completion_fim"}
    boolean completionFim = false;
};

public type ResponseFormat record {|
    @jsondata:Name {value: "json_schema"}
    JsonSchema jsonSchema?;
    # An object specifying the format that the model must output. Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is in JSON. When using JSON mode you MUST also instruct the model to produce JSON yourself with a system or a user message
    ResponseFormats 'type?;
|};

public type UnarchiveFTModelOut record {
    boolean archived = false;
    string id;
    "model" 'object = "model";
};

public type TextChunk record {|
    string text;
    "text" 'type = "text";
|};

public type WandbIntegrationOut record {
    # A display name to set for the run. If not set, will use the job ID as the name
    string? name?;
    # The name of the project that the new run will be created under
    string project;
    "wandb" 'type = "wandb";
    @jsondata:Name {value: "run_name"}
    string? runName?;
};

public type ChatCompletionResponse record {
    *ChatCompletionResponseBase;
    *ChatCompletionResponse1;
};

public type TrainingFile record {
    @jsondata:Name {value: "file_id"}
    string fileId;
    @constraint:Number {minValueExclusive: 0}
    decimal weight = 1;
};

public type FTModelOut record {
    boolean archived;
    FTModelCapabilitiesOut capabilities;
    string[] aliases = [];
    @jsondata:Name {value: "max_context_length"}
    int maxContextLength = 32768;
    int created;
    string root;
    string? name?;
    string? description?;
    @jsondata:Name {value: "owned_by"}
    string ownedBy;
    string id;
    string job;
    "model" 'object = "model";
};

public type ModelListData BaseModelCard|FTModelCard;

public type ClassificationRequest record {|
    # Text to classify
    string|string[] input;
    # ID of the model to use
    string model;
|};

# An object specifying the format that the model must output. Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is in JSON. When using JSON mode you MUST also instruct the model to produce JSON yourself with a system or a user message
public type ResponseFormats "text"|"json_object"|"json_schema";

public type MultiPartBodyParams record {
    # The File object (not file name) to be uploaded.
    #  To upload a file and specify a custom file name you should format your request as such:
    #  ```bash
    #  file=@path/to/your/file.jsonl;filename=custom_name.jsonl
    #  ```
    #  Otherwise, you can just keep the original file name:
    #  ```bash
    #  file=@path/to/your/file.jsonl
    #  ```
    record {byte[] fileContent; string fileName;} file;
    FilePurpose purpose?;
};

public type ContentChunk TextChunk|ImageURLChunk|DocumentURLChunk|ReferenceChunk;

public type ChatCompletionResponseBase record {
    *ResponseBase;
    *ChatCompletionResponseBase1;
};

public type ApiEndpoint "/chat/completions"|"/embeddings"|"/fim/completions"|"/moderations"|"/chat/moderations";

public type BatchJobStatus "QUEUED"|"RUNNING"|"SUCCESS"|"FAILED"|"TIMEOUT_EXCEEDED"|"CANCELLATION_REQUESTED"|"CANCELLED";

public type FIMCompletionResponse record {
    *ChatCompletionResponse;
    string model?;
};

public type DeleteModelOut record {
    # The deletion status
    boolean deleted = true;
    # The ID of the deleted model
    string id;
    # The object type that was deleted
    string 'object = "model";
};

public type OCRUsageInfo record {|
    # Number of pages processed
    @jsondata:Name {value: "pages_processed"}
    int pagesProcessed;
    # Document size in bytes
    @jsondata:Name {value: "doc_size_bytes"}
    int? docSizeBytes?;
|};

public type DetailedJobOut record {
    @jsondata:Name {value: "job_type"}
    string jobType;
    JobMetadataOut metadata?;
    @jsondata:Name {value: "fine_tuned_model"}
    string? fineTunedModel?;
    @jsondata:Name {value: "created_at"}
    int createdAt;
    CheckpointOut[] checkpoints = [];
    string? suffix?;
    @jsondata:Name {value: "auto_start"}
    boolean autoStart;
    @jsondata:Name {value: "training_files"}
    string[] trainingFiles;
    DetailedJobOutRepositories[] repositories = [];
    TrainingParameters hyperparameters;
    # The name of the model to fine-tune
    FineTuneableModel model;
    string id;
    @jsondata:Name {value: "trained_tokens"}
    int? trainedTokens?;
    @jsondata:Name {value: "modified_at"}
    int modifiedAt;
    DetailedJobOutIntegrations[]? integrations?;
    # Event items are created every time the status of a fine-tuning job changes. The timestamped list of all events is accessible here
    EventOut[] events = [];
    "QUEUED"|"STARTED"|"VALIDATING"|"VALIDATED"|"RUNNING"|"FAILED_VALIDATION"|"FAILED"|"SUCCESS"|"CANCELLED"|"CANCELLATION_REQUESTED" status;
    @jsondata:Name {value: "validation_files"}
    string[]? validationFiles = [];
    "job" 'object = "job";
};

public type OCRPageDimensions record {|
    # Width of the image in pixels
    @constraint:Int {minValue: 0}
    int width;
    # Dots per inch of the page-image
    @constraint:Int {minValue: 0}
    int dpi;
    # Height of the image in pixels
    @constraint:Int {minValue: 0}
    int height;
|};

public type UpdateFTModelIn record {
    string? name?;
    string? description?;
};

public type ResponseBase record {
    UsageInfo usage?;
    string model?;
    string id?;
    string 'object?;
};

public type ClassificationResponse record {
    string model?;
    string id?;
    ClassificationObject[] results?;
};

public type FunctionCall record {|
    string name;
    record {}|string arguments;
|};

public type UsageInfo record {
    @jsondata:Name {value: "completion_tokens"}
    int completionTokens;
    @jsondata:Name {value: "prompt_tokens"}
    int promptTokens;
    @jsondata:Name {value: "total_tokens"}
    int totalTokens;
};

public type UploadFileOut record {
    # The name of the uploaded file
    string filename;
    FilePurpose purpose;
    # The size of the file, in bytes
    int bytes;
    # The UNIX timestamp (in seconds) of the event
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The unique identifier of the file
    string id;
    Source 'source;
    @jsondata:Name {value: "sample_type"}
    SampleType sampleType;
    @jsondata:Name {value: "num_lines"}
    int? numLines?;
    # The object type, which is always "file"
    string 'object;
};

# Metrics at the step number during the fine-tuning job. Use these metrics to assess if the training is going smoothly (loss should decrease, token accuracy should increase)
public type MetricOut record {
    @jsondata:Name {value: "valid_loss"}
    decimal? validLoss?;
    @jsondata:Name {value: "valid_mean_token_accuracy"}
    decimal? validMeanTokenAccuracy?;
    @jsondata:Name {value: "train_loss"}
    decimal? trainLoss?;
};

public type BatchJobIn record {
    @jsondata:Name {value: "input_files"}
    string[] inputFiles;
    ApiEndpoint endpoint;
    record {|string...;|}? metadata?;
    @jsondata:Name {value: "timeout_hours"}
    int timeoutHours = 24;
    string model;
};

public type BatchError record {
    int count = 1;
    string message;
};

public type JobsOut record {
    int total;
    JobOut[] data = [];
    "list" 'object = "list";
};

# Represents the Queries record for the operation: files_api_routes_list_files
public type FilesApiRoutesListFilesQueries record {
    string? search?;
    FilePurpose purpose?;
    int page = 0;
    Source[]? 'source?;
    @http:Query {name: "sample_type"}
    SampleType[]? sampleType?;
    @http:Query {name: "page_size"}
    int pageSize = 100;
};

public type ReferenceChunk record {|
    @jsondata:Name {value: "reference_ids"}
    int[] referenceIds;
    "reference" 'type = "reference";
|};

public type OCRImageObject record {|
    # X coordinate of bottom-right corner of the extracted image
    @jsondata:Name {value: "bottom_right_x"}
    int? bottomRightX;
    # Y coordinate of bottom-right corner of the extracted image
    @jsondata:Name {value: "bottom_right_y"}
    int? bottomRightY;
    # Base64 string of the extracted image
    @jsondata:Name {value: "image_base64"}
    string? imageBase64?;
    # Y coordinate of top-left corner of the extracted image
    @jsondata:Name {value: "top_left_y"}
    int? topLeftY;
    # Image ID for extracted image in a page
    string id;
    # X coordinate of top-left corner of the extracted image
    @jsondata:Name {value: "top_left_x"}
    int? topLeftX;
|};

public type SampleType "pretrain"|"instruct"|"batch_request"|"batch_result"|"batch_error";

public type JobInRepositories GithubRepositoryIn;

public type OCRRequest record {|
    # Specific pages user wants to process in various formats: single number, range, or list of both. Starts from 0
    int[]? pages?;
    # Minimum height and width of image to extract
    @jsondata:Name {value: "image_min_size"}
    int? imageMinSize?;
    # Document to run OCR on
    DocumentURLChunk|ImageURLChunk document;
    # Include image URLs in response
    @jsondata:Name {value: "include_image_base64"}
    boolean? includeImageBase64?;
    # Max images to extract
    @jsondata:Name {value: "image_limit"}
    int? imageLimit?;
    string? model;
    string id?;
|};

# Represents the Queries record for the operation: jobs_api_routes_batch_get_batch_jobs
public type JobsApiRoutesBatchGetBatchJobsQueries record {
    record {}? metadata?;
    @http:Query {name: "created_after"}
    string? createdAfter?;
    string? model?;
    int page = 0;
    @http:Query {name: "created_by_me"}
    boolean createdByMe = false;
    @http:Query {name: "page_size"}
    int pageSize = 100;
    BatchJobStatus status?;
};

public type FilePurpose "fine-tune"|"batch";

public type LegacyJobMetadataOut record {
    # The total number of tokens in the training dataset
    @jsondata:Name {value: "data_tokens"}
    int? dataTokens?;
    # The number of tokens consumed by one training step
    @jsondata:Name {value: "train_tokens_per_step"}
    int? trainTokensPerStep?;
    # The cost of the fine-tuning job
    decimal? cost?;
    # The currency used for the fine-tuning job cost
    @jsondata:Name {value: "cost_currency"}
    string? costCurrency?;
    @jsondata:Name {value: "estimated_start_time"}
    int? estimatedStartTime?;
    # The approximated time (in seconds) for the fine-tuning process to complete
    @jsondata:Name {value: "expected_duration_seconds"}
    int? expectedDurationSeconds?;
    boolean deprecated = true;
    string details;
    # The total number of tokens used during the fine-tuning process
    @jsondata:Name {value: "train_tokens"}
    int? trainTokens?;
    # The number of complete passes through the entire training dataset
    decimal? epochs?;
    # The number of training steps to perform. A training step refers to a single update of the model weights during the fine-tuning process. This update is typically calculated using a batch of samples from the training dataset
    @jsondata:Name {value: "training_steps"}
    int? trainingSteps?;
    "job.metadata" 'object = "job.metadata";
};

# this restriction of `Function` is used to select a specific function to call
public type FunctionName record {|
    string name;
|};

public type DeleteFileOut record {
    # The deletion status
    boolean deleted;
    # The ID of the deleted file
    string id;
    # The object type that was deleted
    string 'object;
};

public type DocumentURLChunk record {|
    # The filename of the document
    @jsondata:Name {value: "document_name"}
    string? documentName?;
    string 'type = "document_url";
    @jsondata:Name {value: "document_url"}
    string documentUrl;
|};

public type RetrieveFileOut record {
    # The name of the uploaded file
    string filename;
    boolean deleted;
    FilePurpose purpose;
    # The size of the file, in bytes
    int bytes;
    # The UNIX timestamp (in seconds) of the event
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The unique identifier of the file
    string id;
    Source 'source;
    @jsondata:Name {value: "sample_type"}
    SampleType sampleType;
    @jsondata:Name {value: "num_lines"}
    int? numLines?;
    # The object type, which is always "file"
    string 'object;
};

public type DetailedJobOutIntegrations WandbIntegrationOut;

public type ResponseRetrieveModelV1ModelsModelIdGet BaseModelCard|FTModelCard;

public type ToolMessage record {|
    "tool" role = "tool";
    @jsondata:Name {value: "tool_call_id"}
    string? toolCallId?;
    string? name?;
    string|ContentChunk[]? content;
|};

# Extra fields for fine-tuned models
public type FTModelCard record {
    ModelCapabilities capabilities;
    string[] aliases = [];
    int created?;
    string? description?;
    @jsondata:Name {value: "owned_by"}
    string ownedBy = "mistralai";
    string? deprecation?;
    "fine-tuned" 'type = "fine-tuned";
    boolean archived = false;
    @jsondata:Name {value: "max_context_length"}
    int maxContextLength = 32768;
    string root;
    string? name?;
    @jsondata:Name {value: "default_model_temperature"}
    decimal? defaultModelTemperature?;
    string id;
    string job;
    string 'object = "model";
};

public type Tool record {|
    Function 'function;
    ToolTypes 'type?;
|};

public type BatchJobsOut record {
    int total;
    BatchJobOut[] data = [];
    "list" 'object = "list";
};

public type AssistantMessage record {|
    "assistant" role = "assistant";
    # Set this to `true` when adding an assistant message as prefix to condition the model response. The role of the prefix message is to force the model to start its answer by the content of the message
    boolean prefix = false;
    @jsondata:Name {value: "tool_calls"}
    ToolCall[]? toolCalls?;
    string|ContentChunk[]? content?;
|};

public type Prediction record {|
    string 'type = "content";
    string content = "";
|};

public type GithubRepositoryOut record {
    string owner;
    string? ref?;
    string name;
    @constraint:Number {minValueExclusive: 0}
    decimal weight = 1;
    "github" 'type = "github";
    @jsondata:Name {value: "commit_id"}
    string commitId;
};

public type ChatCompletionResponseBase1 record {
    int created?;
};

public type ImageURL record {|
    string? detail?;
    string url;
|};

public type ChatModerationRequest record {|
    @jsondata:Name {value: "truncate_for_context_length"}
    boolean truncateForContextLength = false;
    # Chat to classify
    (SystemMessage|UserMessage|AssistantMessage|ToolMessage)[]|(SystemMessage|UserMessage|AssistantMessage|ToolMessage)[][] input;
    string model;
|};

public type ModelCapabilities record {
    @jsondata:Name {value: "completion_chat"}
    boolean completionChat = true;
    @jsondata:Name {value: "function_calling"}
    boolean functionCalling = true;
    boolean vision = false;
    @jsondata:Name {value: "fine_tuning"}
    boolean fineTuning = false;
    @jsondata:Name {value: "completion_fim"}
    boolean completionFim = false;
};

public type EmbeddingResponseData record {
    int index?;
    decimal[] embedding?;
    string 'object?;
};

public type ListFilesOut record {
    int total;
    FileSchema[] data;
    string 'object;
};

public type ToolTypes "function";

public type OCRPageObject record {|
    # List of all extracted images in the page
    OCRImageObject[] images;
    # The markdown string response of the page
    string markdown;
    # The page index in a pdf document starting from 0
    @constraint:Int {minValue: 0}
    int index;
    OCRPageDimensions dimensions;
|};

public type JobInIntegrations WandbIntegration;

public type FileSignedURL record {
    string url;
};

# ToolChoice is either a ToolChoiceEnum or a ToolChoice
public type ToolChoice record {|
    # this restriction of `Function` is used to select a specific function to call
    FunctionName 'function;
    ToolTypes 'type?;
|};

# The name of the model to fine-tune
public type FineTuneableModel "open-mistral-7b"|"mistral-small-latest"|"codestral-latest"|"mistral-large-latest"|"open-mistral-nemo"|"ministral-3b-latest";

public type BaseModelCard record {
    ModelCapabilities capabilities;
    string[] aliases = [];
    @jsondata:Name {value: "max_context_length"}
    int maxContextLength = 32768;
    int created?;
    string? name?;
    @jsondata:Name {value: "default_model_temperature"}
    decimal? defaultModelTemperature?;
    string? description?;
    @jsondata:Name {value: "owned_by"}
    string ownedBy = "mistralai";
    string id;
    string? deprecation?;
    "base" 'type = "base";
    string 'object = "model";
};

public type WandbIntegration record {
    # The WandB API key to use for authentication
    @jsondata:Name {value: "api_key"}
    string apiKey;
    # A display name to set for the run. If not set, will use the job ID as the name
    string? name?;
    # The name of the project that the new run will be created under
    string project;
    "wandb" 'type = "wandb";
    @jsondata:Name {value: "run_name"}
    string? runName?;
};

# Represents the Queries record for the operation: files_api_routes_get_signed_url
public type FilesApiRoutesGetSignedUrlQueries record {
    # Number of hours before the url becomes invalid. Defaults to 24h
    int expiry = 24;
};

public type FIMCompletionRequest record {|
    # Nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both
    @jsondata:Name {value: "top_p"}
    decimal topP = 1;
    # The seed to use for random sampling. If set, different calls will generate deterministic results
    @jsondata:Name {value: "random_seed"}
    int? randomSeed?;
    # Stop generation if this token is detected. Or if one of these tokens is detected when providing an array
    string|string[] stop?;
    # The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length
    @jsondata:Name {value: "max_tokens"}
    int? maxTokens?;
    # Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON
    boolean 'stream = false;
    # What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value
    decimal? temperature?;
    # ID of the model to use. Only compatible for now with:
    #   - `codestral-2405`
    #   - `codestral-latest`
    string model = "codestral-2405";
    # Optional text/code that adds more context for the model. When given a `prompt` and a `suffix` the model will fill what is between them. When `suffix` is not provided, the model will simply execute completion starting with `prompt`
    string? suffix = "";
    # The text/code to complete
    string prompt;
    # The minimum number of tokens to generate in the completion
    @jsondata:Name {value: "min_tokens"}
    int? minTokens?;
|};

public type DetailedJobOutRepositories GithubRepositoryOut;

public type AgentsCompletionRequestMessages SystemMessage|UserMessage|AssistantMessage|ToolMessage;

public type SystemMessage record {|
    "system" role = "system";
    string|TextChunk[] content;
|};

public type ChatCompletionResponse1 record {
    ChatCompletionChoice[] choices?;
};

public type AgentsCompletionRequest record {|
    # The seed to use for random sampling. If set, different calls will generate deterministic results
    @jsondata:Name {value: "random_seed"}
    int? randomSeed?;
    # The ID of the agent to use for this completion
    @jsondata:Name {value: "agent_id"}
    string agentId;
    # The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length
    @jsondata:Name {value: "max_tokens"}
    int? maxTokens?;
    # presence_penalty determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative
    @jsondata:Name {value: "presence_penalty"}
    decimal presencePenalty = 0;
    Tool[]? tools?;
    # Number of completions to return for each request, input tokens are only billed once
    int? n?;
    @jsondata:Name {value: "response_format"}
    ResponseFormat responseFormat?;
    # frequency_penalty penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition
    @jsondata:Name {value: "frequency_penalty"}
    decimal frequencyPenalty = 0;
    # Stop generation if this token is detected. Or if one of these tokens is detected when providing an array
    string|string[] stop?;
    # Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON
    boolean 'stream = false;
    Prediction prediction?;
    # The prompt(s) to generate completions for, encoded as a list of dict with role and content
    AgentsCompletionRequestMessages[] messages;
    @jsondata:Name {value: "tool_choice"}
    ToolChoice|ToolChoiceEnum toolChoice = "auto";
|};

public type JobMetadataOut record {
    @jsondata:Name {value: "data_tokens"}
    int? dataTokens?;
    @jsondata:Name {value: "train_tokens_per_step"}
    int? trainTokensPerStep?;
    decimal? cost?;
    @jsondata:Name {value: "cost_currency"}
    string? costCurrency?;
    @jsondata:Name {value: "estimated_start_time"}
    int? estimatedStartTime?;
    @jsondata:Name {value: "expected_duration_seconds"}
    int? expectedDurationSeconds?;
    @jsondata:Name {value: "train_tokens"}
    int? trainTokens?;
};

public type UserMessage record {|
    "user" role = "user";
    string|ContentChunk[]? content;
|};

public type Source "upload"|"repository"|"mistral";

public type ChatCompletionRequest record {|
    # The seed to use for random sampling. If set, different calls will generate deterministic results
    @jsondata:Name {value: "random_seed"}
    int? randomSeed?;
    # Whether to inject a safety prompt before all conversations
    @jsondata:Name {value: "safe_prompt"}
    boolean safePrompt = false;
    # The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length
    @jsondata:Name {value: "max_tokens"}
    int? maxTokens?;
    # presence_penalty determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative
    @jsondata:Name {value: "presence_penalty"}
    decimal presencePenalty = 0;
    Tool[]? tools?;
    # Number of completions to return for each request, input tokens are only billed once
    int? n?;
    # Nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both
    @jsondata:Name {value: "top_p"}
    decimal topP = 1;
    @jsondata:Name {value: "response_format"}
    ResponseFormat responseFormat?;
    # frequency_penalty penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition
    @jsondata:Name {value: "frequency_penalty"}
    decimal frequencyPenalty = 0;
    # Stop generation if this token is detected. Or if one of these tokens is detected when providing an array
    string|string[] stop?;
    # Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON
    boolean 'stream = false;
    # What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value
    decimal? temperature?;
    Prediction prediction?;
    # The prompt(s) to generate completions for, encoded as a list of dict with role and content
    AgentsCompletionRequestMessages[] messages;
    @jsondata:Name {value: "tool_choice"}
    ToolChoice|ToolChoiceEnum toolChoice = "auto";
    # ID of the model to use. You can use the [List Available Models](/api/#tag/models/operation/list_models_v1_models_get) API to see all of your available models, or see our [Model overview](/models) for model descriptions
    string model;
|};

public type ModelList record {
    ModelListData[] data?;
    string 'object = "list";
};

public type Function record {|
    string name;
    string description = "";
    boolean strict = false;
    record {} parameters;
|};

# {"type":"image_url","image_url":{"url":"data:image/png;base64,iVBORw0
public type ImageURLChunk record {|
    @jsondata:Name {value: "image_url"}
    ImageURL|string imageUrl;
    "image_url" 'type = "image_url";
|};

public type ToolChoiceEnum "auto"|"none"|"any"|"required";

public type TrainingParameters record {
    @jsondata:Name {value: "fim_ratio"}
    decimal? fimRatio = 0.9;
    @jsondata:Name {value: "weight_decay"}
    decimal? weightDecay = 0.1;
    @jsondata:Name {value: "training_steps"}
    int? trainingSteps?;
    @jsondata:Name {value: "learning_rate"}
    decimal learningRate = 0.00010;
    decimal? epochs?;
    @jsondata:Name {value: "seq_len"}
    int? seqLen?;
    @jsondata:Name {value: "warmup_fraction"}
    decimal? warmupFraction = 0.05;
};

public type JobOut record {
    # The type of job (`FT` for fine-tuning)
    @jsondata:Name {value: "job_type"}
    string jobType;
    JobMetadataOut metadata?;
    # The name of the fine-tuned model that is being created. The value will be `null` if the fine-tuning job is still running
    @jsondata:Name {value: "fine_tuned_model"}
    string? fineTunedModel?;
    # The UNIX timestamp (in seconds) for when the fine-tuning job was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # Optional text/code that adds more context for the model. When given a `prompt` and a `suffix` the model will fill what is between them. When `suffix` is not provided, the model will simply execute completion starting with `prompt`
    string? suffix?;
    @jsondata:Name {value: "auto_start"}
    boolean autoStart;
    # A list containing the IDs of uploaded files that contain training data
    @jsondata:Name {value: "training_files"}
    string[] trainingFiles;
    DetailedJobOutRepositories[] repositories = [];
    TrainingParameters hyperparameters;
    # The name of the model to fine-tune
    FineTuneableModel model;
    # The ID of the job
    string id;
    # Total number of tokens trained
    @jsondata:Name {value: "trained_tokens"}
    int? trainedTokens?;
    # The UNIX timestamp (in seconds) for when the fine-tuning job was last modified
    @jsondata:Name {value: "modified_at"}
    int modifiedAt;
    # A list of integrations enabled for your fine-tuning job
    DetailedJobOutIntegrations[]? integrations?;
    # The current status of the fine-tuning job
    "QUEUED"|"STARTED"|"VALIDATING"|"VALIDATED"|"RUNNING"|"FAILED_VALIDATION"|"FAILED"|"SUCCESS"|"CANCELLED"|"CANCELLATION_REQUESTED" status;
    # A list containing the IDs of uploaded files that contain validation data
    @jsondata:Name {value: "validation_files"}
    string[]? validationFiles = [];
    # The object type of the fine-tuning job
    "job" 'object = "job";
};

public type JobIn record {
    @jsondata:Name {value: "training_files"}
    TrainingFile[] trainingFiles = [];
    @constraint:Array {maxLength: 50}
    JobInRepositories[] repositories = [];
    # The fine-tuning hyperparameter settings used in a fine-tune job
    TrainingParametersIn hyperparameters;
    # The name of the model to fine-tune
    FineTuneableModel model;
    # A string that will be added to your fine-tuning model name. For example, a suffix of "my-great-model" would produce a model name like `ft:open-mistral-7b:my-great-model:xxx...`
    string? suffix?;
    # A list of integrations to enable for your fine-tuning job
    JobInIntegrations[]? integrations?;
    # A list containing the IDs of uploaded files that contain validation data. If you provide these files, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in `checkpoints` when getting the status of a running fine-tuning job. The same data should not be present in both train and validation files
    @jsondata:Name {value: "validation_files"}
    string[]? validationFiles?;
    # This field will be required in a future release
    @jsondata:Name {value: "auto_start"}
    boolean autoStart?;
};

public type EmbeddingRequest record {|
    # Text to embed
    string|string[] input;
    # ID of the model to use
    string model = "mistral-embed";
|};

public type Response JobOut|LegacyJobMetadataOut;

public type BatchJobOut record {
    @jsondata:Name {value: "succeeded_requests"}
    int succeededRequests;
    record {}? metadata?;
    @jsondata:Name {value: "failed_requests"}
    int failedRequests;
    @jsondata:Name {value: "created_at"}
    int createdAt;
    @jsondata:Name {value: "output_file"}
    string? outputFile?;
    @jsondata:Name {value: "error_file"}
    string? errorFile?;
    @jsondata:Name {value: "input_files"}
    string[] inputFiles;
    @jsondata:Name {value: "completed_at"}
    int? completedAt?;
    string endpoint;
    @jsondata:Name {value: "completed_requests"}
    int completedRequests;
    @jsondata:Name {value: "total_requests"}
    int totalRequests;
    @jsondata:Name {value: "started_at"}
    int? startedAt?;
    string model;
    string id;
    BatchError[] errors;
    "batch" 'object = "batch";
    BatchJobStatus status;
};

public type EmbeddingResponse record {
    *ResponseBase;
    EmbeddingResponseData[] data;
    string id;
    string model;
    string 'object;
    UsageInfo usage;
};

public type ClassificationObject record {
    # Classifier result
    @jsondata:Name {value: "category_scores"}
    record {||} categoryScores?;
    # Classifier result thresholded
    record {|boolean...;|} categories?;
};

public type CheckpointOut record {
    # The step number that the checkpoint was created at
    @jsondata:Name {value: "step_number"}
    int stepNumber;
    # The UNIX timestamp (in seconds) for when the checkpoint was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # Metrics at the step number during the fine-tuning job. Use these metrics to assess if the training is going smoothly (loss should decrease, token accuracy should increase)
    MetricOut metrics;
};
